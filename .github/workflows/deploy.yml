name: PySpark Job CI/CD Pipeline

on:
  push:
    branches:
      - main

jobs:
  build-and-push:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v1

    - name: Set up QEMU
      uses: docker/setup-qemu-action@v1

    - name: Log in to Amazon ECR
      id: ecr-login
      run: |
        aws ecr get-login-password --region ${{ secrets.AWS_REGION }} | docker \
        login --username AWS --password-stdin ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com

    - name: Build and push Docker image
      env:
        ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com
        ECR_REPOSITORY: spark_job_container
        IMAGE_TAG: ${{ github.sha }}

      run: |
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

  deploy:
    runs-on: ubuntu-latest
    needs: build-and-push

    steps:
    - name: Run PySpark job on EMR
      run: |
        aws emr add-steps --cluster-id your-emr-cluster-id \
        --steps Type=CUSTOM_JAR,Name="RunPySparkJob",ActionOnFailure=CONTINUE,Jar=command-runner.jar,\
        Args=["spark-submit","--deploy-mode","cluster","--conf","spark.executor.instances=2","s3a://your-bucket-name/path-to-your-script.py"]
